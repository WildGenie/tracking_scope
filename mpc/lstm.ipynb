{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = loadmat(\"f1data.mat\")\n",
    "\n",
    "x    = mat['x'][:,0]\n",
    "y    = mat['y'][:,0]\n",
    "tail = mat['tail'][:-1,0]\n",
    "\n",
    "input_data = np.stack((x,y)).T\n",
    "output_data = np.stack((x,y)).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 500\n",
    "OUTPUT_SIZE = 50\n",
    "BATCH_SIZE  = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tail To Pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TailToPosGenerator(tf.keras.utils.Sequence):\n",
    "   \n",
    "    def __init__(self, input_data,output_data , input_window_size , output_window_size,batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        self.input_data = input_data\n",
    "        self.output_data = output_data\n",
    "        self.window_size = input_window_size\n",
    "        self.output_size = output_window_size\n",
    "        self.EPOCH_LENGHT = 1000\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "        self.x = np.zeros((self.batch_size,self.window_size,2),dtype=np.float32)\n",
    "        self.y = np.zeros((self.batch_size,self.output_size,2),dtype=np.float32)\n",
    "      \n",
    "    def __len__(self):\n",
    "        return self.EPOCH_LENGHT\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # [batch, timesteps, feature]\n",
    "\n",
    "        idx = self.index[index]\n",
    "\n",
    "        for i in range(idx,idx+self.batch_size):\n",
    "            in_start  = i\n",
    "            in_stop   = in_start + self.window_size\n",
    "            out_start = in_stop\n",
    "            out_stop  = out_start + self.output_size\n",
    "\n",
    "            self.x[i-idx,:,:] = self.input_data[in_start:in_stop]\n",
    "            self.y[i-idx,:,:] = self.output_data[out_start:out_stop,:]\n",
    "            \n",
    "        return self.x, self.y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.index = idx = np.random.randint(low=0,high=self.input_data.shape[0] - (self.batch_size + self.window_size + self.output_size)  , size=self.EPOCH_LENGHT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TailToPosLSTMModel(window_size,output_size):\n",
    "    model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(window_size,2),name='inpt'),\n",
    "    tf.keras.layers.LSTM(64, return_sequences=False,name='lstm'),\n",
    "    tf.keras.layers.Dense(output_size*2,kernel_initializer=tf.initializers.zeros,name='dense'),\n",
    "    tf.keras.layers.Reshape([output_size, 2],name='reshape')\n",
    "    ],name='full_net')\n",
    "\n",
    "    model.compile(\n",
    "                #loss=EuclideanDistanceLoss,\n",
    "                loss=tf.losses.MeanSquaredError(),\n",
    "                optimizer=tf.optimizers.Adam(),\n",
    "                metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EuclideanDistanceLoss(y_true, y_pred):\n",
    "    cumsum_y_true = tf.math.cumsum(y_true, axis=1)\n",
    "    cumsum_y_pred = tf.math.cumsum(y_pred, axis=1)\n",
    "\n",
    "    return tf.norm(cumsum_y_true-cumsum_y_pred, ord='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"full_net\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 64)                17152     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               6500      \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 50, 2)             0         \n",
      "=================================================================\n",
      "Total params: 23,652\n",
      "Trainable params: 23,652\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0587 - mean_absolute_error: 0.1154\n",
      "Epoch 2/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0560 - mean_absolute_error: 0.1128\n",
      "Epoch 3/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0522 - mean_absolute_error: 0.1111\n",
      "Epoch 4/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0550 - mean_absolute_error: 0.1111\n",
      "Epoch 5/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0501 - mean_absolute_error: 0.1090\n",
      "Epoch 6/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0513 - mean_absolute_error: 0.1070\n",
      "Epoch 7/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0506 - mean_absolute_error: 0.1092\n",
      "Epoch 8/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0489 - mean_absolute_error: 0.1056\n",
      "Epoch 9/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0521 - mean_absolute_error: 0.1092\n",
      "Epoch 10/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0538 - mean_absolute_error: 0.1088 2s - loss: 0\n",
      "Epoch 11/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0520 - mean_absolute_error: 0.1090\n",
      "Epoch 12/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0542 - mean_absolute_error: 0.1087\n",
      "Epoch 13/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0503 - mean_absolute_error: 0.1080 1s - loss: 0.0503 - mean_\n",
      "Epoch 14/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0509 - mean_absolute_error: 0.1075\n",
      "Epoch 15/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0529 - mean_absolute_error: 0.1104 5s - loss: 0.051\n",
      "Epoch 16/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0453 - mean_absolute_error: 0.1041\n",
      "Epoch 17/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0491 - mean_absolute_error: 0.1087\n",
      "Epoch 18/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0509 - mean_absolute_error: 0.1079\n",
      "Epoch 19/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0543 - mean_absolute_error: 0.1092\n",
      "Epoch 20/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0555 - mean_absolute_error: 0.1088\n",
      "Epoch 21/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0540 - mean_absolute_error: 0.1097\n",
      "Epoch 22/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0474 - mean_absolute_error: 0.1059\n",
      "Epoch 23/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0495 - mean_absolute_error: 0.1073\n",
      "Epoch 24/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0482 - mean_absolute_error: 0.1079\n",
      "Epoch 25/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0464 - mean_absolute_error: 0.1058\n",
      "Epoch 26/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0482 - mean_absolute_error: 0.1061\n",
      "Epoch 27/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0536 - mean_absolute_error: 0.1089\n",
      "Epoch 28/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0495 - mean_absolute_error: 0.1077\n",
      "Epoch 29/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0469 - mean_absolute_error: 0.1031\n",
      "Epoch 30/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0516 - mean_absolute_error: 0.1097 0s - loss: 0.0513 - mean_absolute_e\n",
      "Epoch 31/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0450 - mean_absolute_error: 0.1032\n",
      "Epoch 32/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0556 - mean_absolute_error: 0.1099\n",
      "Epoch 33/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0462 - mean_absolute_error: 0.1053\n",
      "Epoch 34/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0480 - mean_absolute_error: 0.1078\n",
      "Epoch 35/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0543 - mean_absolute_error: 0.1093\n",
      "Epoch 36/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0534 - mean_absolute_error: 0.1087\n",
      "Epoch 37/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0488 - mean_absolute_error: 0.1072\n",
      "Epoch 38/1000\n",
      "1000/1000 [==============================] - 32s 32ms/step - loss: 0.0520 - mean_absolute_error: 0.1065\n",
      "Epoch 39/1000\n",
      "1000/1000 [==============================] - 32s 32ms/step - loss: 0.0516 - mean_absolute_error: 0.1080\n",
      "Epoch 40/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0474 - mean_absolute_error: 0.1054\n",
      "Epoch 41/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0502 - mean_absolute_error: 0.1079\n",
      "Epoch 42/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0490 - mean_absolute_error: 0.1068\n",
      "Epoch 43/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0442 - mean_absolute_error: 0.1028\n",
      "Epoch 44/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0497 - mean_absolute_error: 0.1064\n",
      "Epoch 45/1000\n",
      "1000/1000 [==============================] - 32s 32ms/step - loss: 0.0458 - mean_absolute_error: 0.1060 1s - loss: 0.0461 - m\n",
      "Epoch 46/1000\n",
      "1000/1000 [==============================] - 32s 32ms/step - loss: 0.0472 - mean_absolute_error: 0.1049\n",
      "Epoch 47/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0501 - mean_absolute_error: 0.1068\n",
      "Epoch 48/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0508 - mean_absolute_error: 0.1083\n",
      "Epoch 49/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0485 - mean_absolute_error: 0.1059\n",
      "Epoch 50/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0494 - mean_absolute_error: 0.1062\n",
      "Epoch 51/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0459 - mean_absolute_error: 0.1046\n",
      "Epoch 52/1000\n",
      "1000/1000 [==============================] - 32s 32ms/step - loss: 0.0479 - mean_absolute_error: 0.1057\n",
      "Epoch 53/1000\n",
      "1000/1000 [==============================] - 32s 32ms/step - loss: 0.0473 - mean_absolute_error: 0.1036\n",
      "Epoch 54/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0466 - mean_absolute_error: 0.1044\n",
      "Epoch 55/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0480 - mean_absolute_error: 0.1044 0s - loss: 0.0480 - mean_absolute_error\n",
      "Epoch 56/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0474 - mean_absolute_error: 0.1054\n",
      "Epoch 57/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0493 - mean_absolute_error: 0.1050\n",
      "Epoch 58/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0536 - mean_absolute_error: 0.1090\n",
      "Epoch 59/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0483 - mean_absolute_error: 0.1058\n",
      "Epoch 60/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0448 - mean_absolute_error: 0.1023\n",
      "Epoch 61/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0464 - mean_absolute_error: 0.1037\n",
      "Epoch 62/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0496 - mean_absolute_error: 0.1065\n",
      "Epoch 63/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0464 - mean_absolute_error: 0.1057 1s - loss: 0.0464 - mean_absolute_e - ETA: 1s - loss: 0.0463 - mean_abso\n",
      "Epoch 64/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0491 - mean_absolute_error: 0.1064\n",
      "Epoch 65/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0513 - mean_absolute_error: 0.1071\n",
      "Epoch 66/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0484 - mean_absolute_error: 0.1043 2s - \n",
      "Epoch 67/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0552 - mean_absolute_error: 0.1067\n",
      "Epoch 68/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0462 - mean_absolute_error: 0.1046\n",
      "Epoch 69/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0481 - mean_absolute_error: 0.1054\n",
      "Epoch 70/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0475 - mean_absolute_error: 0.1052\n",
      "Epoch 71/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0446 - mean_absolute_error: 0.1033\n",
      "Epoch 72/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0465 - mean_absolute_error: 0.1043\n",
      "Epoch 73/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0484 - mean_absolute_error: 0.1062 1s - loss: 0.0479 - mean_a\n",
      "Epoch 74/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0529 - mean_absolute_error: 0.1055 0s - loss: 0.0530 - mean_absolute_error:\n",
      "Epoch 75/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0468 - mean_absolute_error: 0.1046\n",
      "Epoch 76/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0466 - mean_absolute_error: 0.1031\n",
      "Epoch 77/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0471 - mean_absolute_error: 0.1038\n",
      "Epoch 78/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0467 - mean_absolute_error: 0.1049\n",
      "Epoch 79/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0476 - mean_absolute_error: 0.1047\n",
      "Epoch 80/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0436 - mean_absolute_error: 0.1016\n",
      "Epoch 81/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0511 - mean_absolute_error: 0.1045\n",
      "Epoch 82/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0473 - mean_absolute_error: 0.1071\n",
      "Epoch 83/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0455 - mean_absolute_error: 0.1044\n",
      "Epoch 84/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0467 - mean_absolute_error: 0.1039\n",
      "Epoch 85/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0462 - mean_absolute_error: 0.1037\n",
      "Epoch 86/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0472 - mean_absolute_error: 0.1037\n",
      "Epoch 87/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0483 - mean_absolute_error: 0.1045\n",
      "Epoch 88/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0436 - mean_absolute_error: 0.1024\n",
      "Epoch 89/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0490 - mean_absolute_error: 0.1058\n",
      "Epoch 90/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0501 - mean_absolute_error: 0.1067 0s - loss: 0.0500 - mean_absolute_\n",
      "Epoch 91/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0505 - mean_absolute_error: 0.1048\n",
      "Epoch 92/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0513 - mean_absolute_error: 0.1077\n",
      "Epoch 93/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0456 - mean_absolute_error: 0.1034 7s - loss: 0.0457 - ETA: 5s - loss: 0.0448 - mean\n",
      "Epoch 94/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0476 - mean_absolute_error: 0.1033\n",
      "Epoch 95/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0421 - mean_absolute_error: 0.0999\n",
      "Epoch 96/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0465 - mean_absolute_error: 0.1049\n",
      "Epoch 97/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0497 - mean_absolute_error: 0.1067\n",
      "Epoch 98/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0454 - mean_absolute_error: 0.1036\n",
      "Epoch 99/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0505 - mean_absolute_error: 0.1059\n",
      "Epoch 100/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0456 - mean_absolute_error: 0.1031\n",
      "Epoch 101/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0502 - mean_absolute_error: 0.1061\n",
      "Epoch 102/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0489 - mean_absolute_error: 0.1056\n",
      "Epoch 103/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0447 - mean_absolute_error: 0.1025 0s - loss: 0.0448 - mean_absolute\n",
      "Epoch 104/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0472 - mean_absolute_error: 0.1058\n",
      "Epoch 105/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0450 - mean_absolute_error: 0.1031\n",
      "Epoch 106/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0458 - mean_absolute_error: 0.1048\n",
      "Epoch 107/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0468 - mean_absolute_error: 0.1043 0s - loss: 0.0469 - mean_absolute_error: 0\n",
      "Epoch 108/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0466 - mean_absolute_error: 0.1047\n",
      "Epoch 109/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0466 - mean_absolute_error: 0.1046\n",
      "Epoch 110/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0418 - mean_absolute_error: 0.0999\n",
      "Epoch 111/1000\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.0445 - mean_absolute_error: 0.1030\n",
      "Epoch 112/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0452 - mean_absolute_error: 0.1040\n",
      "Epoch 113/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0481 - mean_absolute_error: 0.1048\n",
      "Epoch 114/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0459 - mean_absolute_error: 0.1031\n",
      "Epoch 115/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0465 - mean_absolute_error: 0.1054\n",
      "Epoch 116/1000\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0538 - mean_absolute_error: 0.1069\n",
      "Epoch 117/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0426 - mean_absolute_error: 0.0995\n",
      "Epoch 118/1000\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0439 - mean_absolute_error: 0.1010\n",
      "Epoch 119/1000\n",
      " 173/1000 [====>.........................] - ETA: 27s - loss: 0.0457 - mean_absolute_error: 0.1034"
     ]
    }
   ],
   "source": [
    "model = TailToPosLSTMModel( window_size = WINDOW_SIZE, output_size = OUTPUT_SIZE)\n",
    "\n",
    "gen =TailToPosGenerator(input_data,output_data,WINDOW_SIZE,OUTPUT_SIZE,BATCH_SIZE)\n",
    "\n",
    "model.fit(gen,epochs= 1000,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.zeros((1,WINDOW_SIZE,3),dtype=np.float32)\n",
    "ty = np.zeros((1,OUTPUT_SIZE,3),dtype=np.float32)\n",
    "\n",
    "start  = 134\n",
    "t[0,:,:] = data[start:start+WINDOW_SIZE]\n",
    "ty[0,:,:] = data[start+WINDOW_SIZE:start+WINDOW_SIZE+OUTPUT_SIZE]\n",
    "\n",
    "y  = model(t)\n",
    "\n",
    "print(t.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.asarray(range(window_size))\n",
    "xx = np.asarray(range(window_size,window_size + output_size))\n",
    "\n",
    "\n",
    "N = data.shape[1]\n",
    "for i in range(N):\n",
    "    plt.figure(figsize=(30,2))\n",
    "    plt.suptitle(data.columns[i], fontsize=20)\n",
    "    plt.plot(x,t[0,:,i])\n",
    "    plt.plot(xx,y[0,:,i],color='green')\n",
    "    plt.plot(xx,ty[0,:,i],color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.asarray(range(WINDOW_SIZE))\n",
    "xx = np.asarray(range(WINDOW_SIZE,WINDOW_SIZE + OUTPUT_SIZE))\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "    plt.figure(figsize=(30,2))\n",
    "    plt.plot(x,  t[0,:,i])\n",
    "    plt.plot(xx,ty[0,:,i],color='green')\n",
    "    plt.plot(xx, y[0,:,i],color='red')\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevx = np.cumsum(np.squeeze(t[0,:,0]))\n",
    "prevy = np.cumsum(np.squeeze(t[0,:,1]))\n",
    "\n",
    "trux = prevx[-1] + np.cumsum(np.squeeze(ty[0,:,0]))\n",
    "truy = prevy[-1] + np.cumsum(np.squeeze(ty[0,:,1]))\n",
    "\n",
    "predx = prevx[-1] + np.cumsum(np.squeeze())\n",
    "predy = prevy[-1] + np.cumsum(np.squeeze(y[0,:,1]))\n",
    "\n",
    "\n",
    "plt.plot(prevx,prevy,color='blue')\n",
    "plt.plot(trux,truy,color='green')\n",
    "# plt.plot(predx,predy,color='red')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.05200195 -0.02529907]\n",
      "  [ 0.02697754 -0.04050446]\n",
      "  [-0.05187988  0.02540588]\n",
      "  [ 0.05187988 -0.02540588]\n",
      "  [ 0.          0.        ]]\n",
      "\n",
      " [[ 0.02697754 -0.04050446]\n",
      "  [-0.05187988  0.02540588]\n",
      "  [ 0.05187988 -0.02540588]\n",
      "  [ 0.          0.        ]\n",
      "  [ 0.          0.        ]]\n",
      "\n",
      " [[-0.05187988  0.02540588]\n",
      "  [ 0.05187988 -0.02540588]\n",
      "  [ 0.          0.        ]\n",
      "  [ 0.          0.        ]\n",
      "  [ 0.04351807 -0.01239777]]]\n",
      "tf.Tensor(\n",
      "[[[ 0.05200195 -0.02529907]\n",
      "  [ 0.07897949 -0.06580353]\n",
      "  [ 0.02709961 -0.04039764]\n",
      "  [ 0.07897949 -0.06580353]\n",
      "  [ 0.07897949 -0.06580353]]\n",
      "\n",
      " [[ 0.02697754 -0.04050446]\n",
      "  [-0.02490234 -0.01509857]\n",
      "  [ 0.02697754 -0.04050446]\n",
      "  [ 0.02697754 -0.04050446]\n",
      "  [ 0.02697754 -0.04050446]]\n",
      "\n",
      " [[-0.05187988  0.02540588]\n",
      "  [ 0.          0.        ]\n",
      "  [ 0.          0.        ]\n",
      "  [ 0.          0.        ]\n",
      "  [ 0.04351807 -0.01239777]]], shape=(3, 5, 2), dtype=float32)\n",
      "tf.Tensor(0.6945555, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "gen =TailToPosGenerator(input_data,output_data,10,5,3)\n",
    "\n",
    "x,y = gen[0]\n",
    "\n",
    "\n",
    "# print('x',x,x.shape)\n",
    "# print('y',y,y.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(y)\n",
    "print(cm)\n",
    "\n",
    "\n",
    "l2_norm = tf.norm(y-y*5, ord='euclidean')\n",
    "\n",
    "print(l2_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
